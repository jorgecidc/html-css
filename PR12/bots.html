<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="es">
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
    <title>bots</title>
</head>
<body>
    <h1>La guerra de los ´bots`se libra en Wikipedia</h1>
    <h2>Hasta 4,7 millones de los cambios que se hacen en la enciclopedia digital son correcciones que los robots se hacen continuamente entre sí.</h2>
    <hr />
    <div>
       <img  src="img/logos/fb logo.png" alt="Facebook logo" /><img  src="img/logos/tw logo.png" alt="Twitter logo" /><img src="img/logos/share logo.png" alt="Share" />        
    </div>
    <hr />
    <p><strong>M.VICTORIA S.NADAL <img src="img/logos/logo tw 2.png" alt="Logo tw" /></strong></p>
    <p><a href="https://elpais.com/hemeroteca/2016-10-25/">Madrid - 24 oct 2016 - 18:48 CEST</a></p>
    <div>
        <img width="100%" src="img/Wikipedia.png" alt="Periodico" /><br />
        <p align="right">Captura de pantalla de la pagina de inicio de Wikipedia en su 15 cumpleaños</p>
    </div>
    <hr />
    
    <p>Cada vez son más las páginas web que incorporan bots, programas informáticos que se comportan como humanos, para realizar tareas como responder a las preguntas de los usuarios, hacer publicidad o abrir cuentas de correo electrónico. Pero, a pesar de los esfuerzos y de su uso extendido, aún están muy lejos de actuar en la Red como lo haría una persona. Esa es la conclusión a la que ha llegado un grupo de ingenieros informáticos del Instituto Alan Turing de Reino Unido, que <a href="https://www.academia.edu/28502996/Even_Good_Bots_Fight">ha estudiado el comportamiento de estos robots en Wikipedia</a> y ha descubierto que hasta 4,7 millones de las ediciones de los artículos son correcciones que los bots se hacen constantemente entre sí, cayendo en una especie de edición sin fin nada productiva.</p>
    

    <div>
        <img align="right" width="25%" src="./img/wikipedia foto.png" alt="Wikipedia" />
        <p><a href="https://elpais.com/tecnologia/2016/01/15/actualidad/1452854593_728014.html">Los bots que trabajan en Wikipedia</a> se encargan de tareas que pueden resultar tediosas para las personas, como identificar y deshacer casos de vandalismo, añadir enlaces, corregir la ortografía y guardar la concordancia sintáctica de las oraciones. El problema viene cuando las ediciones que hacen están condicionadas por el país y el lenguaje en el que han sido programados y están influidas por algunos aspectos culturales. Por ejemplo, algunas de estas reversiones vienen por cambiar “<a href="https://elpais.com/noticias/palestina/">Palestina</a>” por “territorio palestino” o “Golfo Pérsico” por “Golfo Arábico”, y así con varios millones de conceptos que no coinciden en las distintas regiones del mundo.</p>
    </div>
    <br clear="right" />

    <p>Además, están programados para revisar los cambios que hacen cada cierto tiempo, lo que ayuda a que se produzcan enfrentamientos con otros bots que hacen exactamente lo mismo y se corrigen entre sí cuando encuentran que su última edición ha vuelto a ser modificada. En los cambios que hacen las personas no se dan este tipo de conflictos porque los usuarios de <a href="https://elpais.com/noticias/wikipedia/">Wikipedia</a> rara vez vuelven a comprobar si los datos que corrigieron están actualizados.</p>

    <p>Algunos conflictos, como los de Wikipedia, pueden considerarse inocuos. Otros son más problemáticos y virales, como el que sucedió en Twitter en marzo de este año, cuando <a href="https://elpais.com/tecnologia/2016/03/24/actualidad/1458855274_096966.html">Microsoft tuvo que retirar a uno de su bots</a> por tuitear mensajes de contenido racista, sexista y xenófobo. Había sido programado para contestar preguntas y establecer conversaciones con los más jóvenes de la red y aprendió de ellos este comportamiento.</p>

</body>
</html>




